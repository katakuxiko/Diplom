package main

import (
	"context"
	"database/sql"
	"fmt"
	"log"
	"os"
	"path/filepath"
	"strings"

	"github.com/gofiber/fiber/v2"
	_ "github.com/lib/pq"
	"github.com/sashabaranov/go-openai"
	"rsc.io/pdf"
)

type Chunk struct {
	ID   string `json:"id"`
	Text string `json:"text"`
}

type PgStore struct {
	db *sql.DB
}

var (
	store   *PgStore
	oaicl   *openai.Client
	ctx     = context.Background()
	embedSz = 768 // —Ä–∞–∑–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è embeddings
)

// ---------------- MAIN ----------------
func main() {
	// –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Postgres
	connStr := "host=localhost port=5432 user=postgres password=123123 dbname=pdf_ai sslmode=disable"
	db, err := sql.Open("postgres", connStr)
	if err != nil {
		log.Fatal("–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î:", err)
	}
	store = &PgStore{db: db}

	// LM Studio client (OpenAI —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π)
	config := openai.DefaultConfig("not-needed")
	config.BaseURL = "http://localhost:1234/v1" // LM Studio API
	oaicl = openai.NewClientWithConfig(config)

	// API
	app := fiber.New()
	app.Post("/ingest", ingestPDF)
	app.Post("/ask", askQuestion)

	log.Println("üöÄ Server started at http://localhost:8080")
	log.Fatal(app.Listen(":8080"))
}

// ---------------- HANDLERS ----------------

// –ó–∞–≥—Ä—É–∑–∫–∞ PDF –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–∞–Ω–∫–æ–≤
func ingestPDF(c *fiber.Ctx) error {
	file, err := c.FormFile("file")
	if err != nil {
		return c.Status(400).SendString("–§–∞–π–ª –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω")
	}

	savePath := filepath.Join("data", "pdfs", file.Filename)
	os.MkdirAll(filepath.Dir(savePath), os.ModePerm)
	if err := c.SaveFile(file, savePath); err != nil {
		return c.Status(500).SendString("–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞")
	}

	text, err := extractText(savePath)
	if err != nil {
		return c.Status(500).SendString("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è PDF")
	}

	chunks := chunkText(text, 800, 200)
    for i, ch := range chunks {
        emb, err := getEmbedding(ch.Text)
		fmt.Println("Embedding length:", len(emb))
        if err != nil || len(emb) == 0 {
            log.Println("–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è embedding:", err)
            continue // –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç —á–∞–Ω–∫
        }
        ch.ID = fmt.Sprintf("%s_chunk_%d", file.Filename, i)
        if err := store.Add(ch, emb); err != nil {
            log.Println("–û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏:", err)
        }
    }

	return c.JSON(fiber.Map{"status": "ok", "chunks": len(chunks)})
}

// –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
type AskRequest struct {
	Query string `json:"query"`
}

func askQuestion(c *fiber.Ctx) error {
	var req AskRequest
	if err := c.BodyParser(&req); err != nil {
		return c.Status(400).SendString("–ù–µ–≤–µ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å")
	}

	qVec, _ := getEmbedding(req.Query)
	top, _ := store.Search(qVec, 5)

	var contextText strings.Builder
	for _, t := range top {
		contextText.WriteString("[" + t.ID + "]\n" + t.Text + "\n\n")
	}

	answer, err := askGemma(req.Query, contextText.String())
	if err != nil {
		fmt.Println("–û—à–∏–±–∫–∞ Gemma:", err)
		return c.Status(500).SendString("–û—à–∏–±–∫–∞ Gemma")
	}

	return c.JSON(fiber.Map{
		"answer":  answer,
		"context": top,
	})
}

// ---------------- PDF UTILS ----------------
func extractText(path string) (string, error) {
    r, err := pdf.Open(path)
    if err != nil {
        return "", err
    }
    var sb strings.Builder
    for i := 1; i <= r.NumPage(); i++ {
        p := r.Page(i)
        if p.V.IsNull() {
            continue
        }
        texts := p.Content().Text
        for _, t := range texts {
            // –£–¥–∞–ª—è–µ–º –Ω—É–ª–µ–≤—ã–µ –±–∞–π—Ç—ã
            clean := strings.ReplaceAll(t.S, "\x00", "")
            sb.WriteString(clean)
        }
        sb.WriteString("\n")
    }
    return sb.String(), nil
}
// ...existing code...

func chunkText(text string, size, overlap int) []Chunk {
	var chunks []Chunk
	words := strings.Fields(text)
	for i := 0; i < len(words); i += (size - overlap) {
		end := i + size
		if end > len(words) {
			end = len(words)
		}
		chunks = append(chunks, Chunk{Text: strings.Join(words[i:end], " ")})
		if end == len(words) {
			break
		}
	}
	return chunks
}

// ---------------- EMBEDDINGS ----------------
func getEmbedding(text string) ([]float32, error) {
	resp, err := oaicl.CreateEmbeddings(ctx, openai.EmbeddingRequest{
		Model: "nomic-embed-text", // –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –≤ LM Studio
		Input: []string{text},
	})
	if err != nil {
		return nil, err
	}
	return resp.Data[0].Embedding, nil
}

// ---------------- POSTGRES STORE ----------------
func (s *PgStore) Add(c Chunk, v []float32) error {
	vec := floatsToPgArray(v)
	_, err := s.db.Exec(`
		INSERT INTO chunks (doc_name, chunk_id, text, embedding)
		VALUES ($1, $2, $3, $4::vector)
	`, "doc", c.ID, c.Text, vec)
	return err
}

func (s *PgStore) Search(q []float32, topK int) ([]Chunk, error) {
	vec := floatsToPgArray(q)
	rows, err := s.db.Query(`
		SELECT chunk_id, text
		FROM chunks
		ORDER BY embedding <-> $1::vector
		LIMIT $2
	`, vec, topK)
	if err != nil {
		return nil, err
	}
	defer rows.Close()

	var results []Chunk
	for rows.Next() {
		var c Chunk
		if err := rows.Scan(&c.ID, &c.Text); err != nil {
			return nil, err
		}
		results = append(results, c)
	}
	return results, nil
}

func floatsToPgArray(v []float32) string {
	var sb strings.Builder
	sb.WriteString("[")
	for i, val := range v {
		// –õ—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å %.6f, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å –ª–∏—à–Ω–∏–º–∏ –∑–Ω–∞–∫–∞–º–∏
		sb.WriteString(fmt.Sprintf("%.6f", val))
		if i < len(v)-1 {
			sb.WriteString(",")
		}
	}
	sb.WriteString("]")
	return sb.String()
}

// ---------------- GEMMA ----------------
func askGemma(query, context string) (string, error) {
	resp, err := oaicl.CreateChatCompletion(ctx, openai.ChatCompletionRequest{
		Model: "google/gemma-3n-e4b", // –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω–∞ –≤ LM Studio
		Messages: []openai.ChatCompletionMessage{
			{Role: "system", Content: "–¢—ã —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—Å–∫–∏–π –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."},
			{Role: "user", Content: fmt.Sprintf("–ö–æ–Ω—Ç–µ–∫—Å—Ç:–¢–ï–°–¢\n\n–í–æ–ø—Ä–æ—Å: %s", context)},
		},
		Temperature: 0.2,
	})
	if err != nil {
		return "", err
	}
	return resp.Choices[0].Message.Content, nil
}
